{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP \n",
    "***\n",
    "Natural Language, Artificial Language\n",
    "1. understanding: 컴퓨터가 언어를 이해할 수 있도록 \n",
    "2. generation: 컴퓨터가 사람이 이해하도록 언어를 생성 \n",
    "\n",
    "\n",
    "## understanding\n",
    "1. 텍스트가 들어오면 정보를 뽑아서 테이블을 채운다라고 하면 sementic 분석을 해서 저장한다. \n",
    "2. 인간이 텍스트로 저장되어있는 정보를 어떻게 이해하는가에 대해서 알고 싶어한다. \n",
    "\n",
    "\n",
    "__* 학습을 위한 데이터가 중요__\n",
    "\n",
    "\n",
    "1. 요소 기술 component: 단어를 알아야 한다. \n",
    "2. integration: 단어를 통한 문맥 이용 \n",
    "3. transfer를 통해 응용을 할 수 있어야 한다. (insight를 가지고 있기 때문에 응용이 가능하다.)\n",
    "- 이러한 학습을 기계가 어떻게 하는지 알아야 한다. : neural science, entropology\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### General steps in NLP\n",
    "\n",
    "1. processing\n",
    "    - 전처리 \n",
    "2. Lexical Analysis 이 단어가 어떤 정보를 가지고 있느냐\n",
    "    1. word, 품사, 문자를 구분 \n",
    "3. Syntentic Analysis\n",
    "    - 주어 목적어, 수식어 \n",
    "4. Sementic Analysis\n",
    "    - 의미, 문맥상의 의미 \n",
    "    - 문장 안에서의 단어의 의미\n",
    "5. Discouse Analysis\n",
    "    - 문장과 문장 간의 관계 \n",
    "    - 대화 안에서의 여러 문장 간의 관계 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__* a space odessay__\n",
    "\n",
    "### NLP가 어려운 이유\n",
    "\n",
    "\n",
    "1. __ambiguous__\n",
    "    - 중의성, 모호성 \n",
    "    - 하나의 unit, constitution이 2개의 의미로 해석이 가능할 때 \n",
    "\n",
    "Time flies like an arrow\n",
    "1. 시간 파리들은 화살을 좋아한다.\n",
    "2. 화살 같은 시간 파리(화살 모양으로 생긴)\n",
    "3. 시간을 화살과 같이 지나간다. \n",
    "\n",
    "\n",
    "lexical를 정하는 구간에서 resolution을 한다고 해도 \n",
    "syntetic, sementic에서도 모호성이 발생할 수 있다. \n",
    "\n",
    "\n",
    "Mother: 어머니, 효모라는 언어로 이용된다. \n",
    "\n",
    "### How to resolve ambiguity\n",
    "\n",
    "1. We need\n",
    "    - Knowledge about language: 언어에 관한 지식 (dict, grammar, example)\n",
    "    - Knowledge about the world: 세상에 관한 지식 (common sense) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question\n",
    "### Q1.  한국어와 영어 중 어려운 언어는?\n",
    "- 한국어가 생산성이 높기 때문에 만들어낼 수 있는 단어가 무한하다.\n",
    "- word embeding이 어렵다. \n",
    "- 어절이 아닌 형태소로 구분을 해서 학습시켜야 한다. \n",
    "- 한국어를 형태소로 자른다고 해도 ambiguity 가능성이 매우 높다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. NLP를 위한 최적의 성능 알고리즘을 선택하는 종류\n",
    "1. 규칙 기반(symbolic): 거의 쓰지 않는다. 데모용 - rule-based\n",
    "2. statistical emperical, 경험 주의적인 \n",
    "3. hybrid\n",
    "4. deep learning - imperical: 성능이 좋지만 왜 이렇게 되었는지 설명이 안된다. blackbox의 문제가 발생한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Major Issuses for NLP\n",
    "1. How to __acquire__ necessary knowledge?\n",
    "2. How to use such knowledge for __resolving ambiguity__?\n",
    "3. How to __represent__ the knowledge?\n",
    "\n",
    "### Two approaches\n",
    "1. symbolic(or rule-based, rational)\n",
    "    - 시스템을 쉽게 만들 수 있다. \n",
    "    - 대부분 상황에 대해서 규칙을 만든다. \n",
    "    - 적용 범위가 한계가 있다. \n",
    "    - 규칙이 적용되는 현상에 대해서는 100%의 정확도를 가진다.\n",
    "    - 언어학자, 개발자들이 규칙을 계속 생성해야한다.\n",
    "    - 규칙이 들어감으로써 다른 되던 것이 안될 수도 있다. (trade off의 상황이 발생할 수 있다.)\n",
    "2. statistical approach(Empirical)- samples \n",
    "    - 정확도가 떨어진다.\n",
    "    - 적용 범위가 넓다.\n",
    "    - 학습을 하기 위해서는 학습 corpurs가 필요하다. \n",
    "    - 수작업이 없지만 training data가 필요하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP applications\n",
    "1. text Categorazation (Classification)\n",
    "    - spam mail recognition, 문서 class assign \n",
    "2. Spelling & Grammar Corrections\n",
    "    - 자동 완성 기능 \n",
    "    - 문법 교정 시스템\n",
    "3. Information Extraction\n",
    "    - 성향 분석, 집단 분석을 통해서 지능형 학습 시스템-학생으로 맞춤형 학습을 시키기 위해서 feature값으로 만들고 유형을 만들어서 clustering을 한 다음에 contents를 추천\n",
    "    - mess customization\n",
    "    - user understanding 필요: 맞춤형 의료 서비스 (profiling)\n",
    "4. Speech Recognition\n",
    "    - Spoken data\n",
    "    - STT, TTS와 모든 interface \n",
    "5. Information Retrieval\n",
    "    - 맞춤형 기사\n",
    "6. Summerization\n",
    "    - abstraction \n",
    "7. Machine Translation\n",
    "    - 현재 많이 발전한 것처럼 보이지만 아직 남아있는 것이 많고 더욱 발전되어야 한다.\n",
    "8. Question Answering\n",
    "    - 차세대 검색 시스템\n",
    "    - QA관련 시스템만 만들어도 차세대 구글이 된다.\n",
    "    - 현재: 알고싶은 information 검색어와 가장 연관이 되어있다라고 판단되는 검색어를 유사도 통해서 sorting을 해서 top10개를 출력 \n",
    "    - 현재: 내가 찾고 싶은 것은 browsing을 해서 일일이 찾아야 한다. \n",
    "    - 질문하면 정확한 답변을 하는 시스템으로 검색 엔진이 필요없어진다. \n",
    "    - knowledge reference, deep learning, \n",
    "9. Dialog Systems\n",
    "    - chat bot \n",
    "    - virtual assitance \n",
    "    - context를 유지하면서 사용자의 목표가 끝날 때까지 multi-turn이 되는 대화를 만들어내야한다. __(clova) - 연계가 된다__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering: unsupervised VS Classification: supervised \n",
    "- Clustering: 모양이나 색깔로 비슷한 류의 아이템들로 그룹핑하는 것 \n",
    "- Classification: 충성 고객, 이탈 고객, 중립 고객으로 그룹핑을 해서 이름을 붙힌다. 그리고 나서 새로운 고객을 분석하여 어떠한 그룹에 해당되는지 분류 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Preprocessing\n",
    "1. 띄어쓰기\n",
    "    1. symbolic: space 규칙을 만든다 - 규칙 충돌의 문제 발생\n",
    "    2. __statictical__\n",
    "        - 어떤 것이 더 probable, 확률적으로 그럴싸한 것을 선택한다. \n",
    "        - mm을 통해서 앞에 단어들이 나오고 나서 뒤에 나올 확률 조건부 확률을 구한다. \n",
    "        - 미리 확률을 계산해야 한다. 정보들을 카운팅해서 나와야 한다. 어떠한 결과는 만들어낼 수 있지만 틀릴 수 있다. \n",
    "        - 어떠한 입력해도 결과가 나온다(robust)\n",
    "2. 철자 교정 \n",
    "\n",
    "## Lexical Processing\n",
    "1. Morphological Analysis __형태소__ 분석기\n",
    "    1. 단어가 하나 생성되면 단어가 이용되는 모든 가능성을 다 집어넣어야 한다. \n",
    "    2. 하지만 한국어는 표제어를 모든 어절을 다 embeding을 할 수 없다. 그래서 형태소 단위로 입력한다.\n",
    "    3. 새로운 단어 하나를 입력한다. (표제어 등록)\n",
    "    4. 그래서 어절이 아닌 형태소를 통해서 어절을 구분한다. \n",
    "2. POS tagging 품사 태깅\n",
    "    1. 각각의 형태소에 맞는 품사를 태깅한다. \n",
    "    2. HMM method \n",
    "    \n",
    "## Named Entity Recognition (NER)\n",
    "1. person, oraganization, time, place, money \n",
    "2. 각각의 단어들의 entity라는 것을 의미한다. \n",
    "    \n",
    "## Syntax Analysis\n",
    "1. frage structure grammar\n",
    "    - 문장의 구조를 완전히 파아\n",
    "2. shallow \n",
    "    - 동사를 기준으로 dependency\n",
    "3. Syntax Net\n",
    "4. Syntactic Parsing\n",
    "    - PCFG: 규칙이 이용되는 확률을 product해서 max를 구하는 방법규칙기반 \n",
    "\n",
    "## Sementic Analysis\n",
    "1. World Sense Disambiguation\n",
    "2. Speech Role Labeling (SRL)\n",
    "    - 능동태와 수동태는 행위자와 수혜자는 동일하다.\n",
    "    - 문장의 sementic 역할을 알아야 한다.\n",
    "    - 이를 통해서 senetece의 role을 알 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
