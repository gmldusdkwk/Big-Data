{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext version_information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "Software versions": [
        {
         "module": "Python",
         "version": "3.6.5 64bit [GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]"
        },
        {
         "module": "IPython",
         "version": "6.4.0"
        },
        {
         "module": "OS",
         "version": "Darwin 17.7.0 x86_64 i386 64bit"
        },
        {
         "module": "numpy",
         "version": "1.13.0"
        },
        {
         "module": "scipy",
         "version": "1.1.0"
        },
        {
         "module": "sklearn",
         "version": "0.19.1"
        },
        {
         "module": "pandas",
         "version": "0.23.0"
        },
        {
         "module": "matplotlib",
         "version": "2.2.2"
        },
        {
         "module": "seaborn",
         "version": "0.8.1"
        }
       ]
      },
      "text/html": [
       "<table><tr><th>Software</th><th>Version</th></tr><tr><td>Python</td><td>3.6.5 64bit [GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]</td></tr><tr><td>IPython</td><td>6.4.0</td></tr><tr><td>OS</td><td>Darwin 17.7.0 x86_64 i386 64bit</td></tr><tr><td>numpy</td><td>1.13.0</td></tr><tr><td>scipy</td><td>1.1.0</td></tr><tr><td>sklearn</td><td>0.19.1</td></tr><tr><td>pandas</td><td>0.23.0</td></tr><tr><td>matplotlib</td><td>2.2.2</td></tr><tr><td>seaborn</td><td>0.8.1</td></tr><tr><td colspan='2'>Wed Aug 08 10:10:11 2018 KST</td></tr></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{|l|l|}\\hline\n",
       "{\\bf Software} & {\\bf Version} \\\\ \\hline\\hline\n",
       "Python & 3.6.5 64bit [GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE\\_401/final)] \\\\ \\hline\n",
       "IPython & 6.4.0 \\\\ \\hline\n",
       "OS & Darwin 17.7.0 x86\\_64 i386 64bit \\\\ \\hline\n",
       "numpy & 1.13.0 \\\\ \\hline\n",
       "scipy & 1.1.0 \\\\ \\hline\n",
       "sklearn & 0.19.1 \\\\ \\hline\n",
       "pandas & 0.23.0 \\\\ \\hline\n",
       "matplotlib & 2.2.2 \\\\ \\hline\n",
       "seaborn & 0.8.1 \\\\ \\hline\n",
       "\\hline \\multicolumn{2}{|l|}{Wed Aug 08 10:10:11 2018 KST} \\\\ \\hline\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "Software versions\n",
       "Python 3.6.5 64bit [GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]\n",
       "IPython 6.4.0\n",
       "OS Darwin 17.7.0 x86_64 i386 64bit\n",
       "numpy 1.13.0\n",
       "scipy 1.1.0\n",
       "sklearn 0.19.1\n",
       "pandas 0.23.0\n",
       "matplotlib 2.2.2\n",
       "seaborn 0.8.1\n",
       "Wed Aug 08 10:10:11 2018 KST"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%version_information numpy, scipy, sklearn, pandas, matplotlib, seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "heeyeonlim Wed Aug 08 2018 \n",
      "\n",
      "IPython 6.4.0\n",
      "numpy 1.13.0\n",
      "scipy 1.1.0\n",
      "sklearn 0.19.1\n",
      "pandas 0.23.0\n",
      "matplotlib 2.2.2\n",
      "seaborn 0.8.1\n"
     ]
    }
   ],
   "source": [
    "%watermark -a heeyeonlim -n -p IPython,numpy,scipy,sklearn,pandas,matplotlib,seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def load_iris(return_X_y=False):\n",
      "    \"\"\"Load and return the iris dataset (classification).\n",
      "\n",
      "    The iris dataset is a classic and very easy multi-class classification\n",
      "    dataset.\n",
      "\n",
      "    =================   ==============\n",
      "    Classes                          3\n",
      "    Samples per class               50\n",
      "    Samples total                  150\n",
      "    Dimensionality                   4\n",
      "    Features            real, positive\n",
      "    =================   ==============\n",
      "\n",
      "    Read more in the :ref:`User Guide <datasets>`.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    return_X_y : boolean, default=False.\n",
      "        If True, returns ``(data, target)`` instead of a Bunch object. See\n",
      "        below for more information about the `data` and `target` object.\n",
      "\n",
      "        .. versionadded:: 0.18\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    data : Bunch\n",
      "        Dictionary-like object, the interesting attributes are:\n",
      "        'data', the data to learn, 'target', the classification labels,\n",
      "        'target_names', the meaning of the labels, 'feature_names', the\n",
      "        meaning of the features, and 'DESCR', the\n",
      "        full description of the dataset.\n",
      "\n",
      "    (data, target) : tuple if ``return_X_y`` is True\n",
      "\n",
      "        .. versionadded:: 0.18\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    Let's say you are interested in the samples 10, 25, and 50, and want to\n",
      "    know their class name.\n",
      "\n",
      "    >>> from sklearn.datasets import load_iris\n",
      "    >>> data = load_iris()\n",
      "    >>> data.target[[10, 25, 50]]\n",
      "    array([0, 0, 1])\n",
      "    >>> list(data.target_names)\n",
      "    ['setosa', 'versicolor', 'virginica']\n",
      "    \"\"\"\n",
      "    module_path = dirname(__file__)\n",
      "    data, target, target_names = load_data(module_path, 'iris.csv')\n",
      "\n",
      "    with open(join(module_path, 'descr', 'iris.rst')) as rst_file:\n",
      "        fdescr = rst_file.read()\n",
      "\n",
      "    if return_X_y:\n",
      "        return data, target\n",
      "\n",
      "    return Bunch(data=data, target=target,\n",
      "                 target_names=target_names,\n",
      "                 DESCR=fdescr,\n",
      "                 feature_names=['sepal length (cm)', 'sepal width (cm)',\n",
      "                                'petal length (cm)', 'petal width (cm)'])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(inspect.getsource(load_iris))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.__dict__ # attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DESCR', 'data', 'feature_names', 'target', 'target_names']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris Plants Database\n",
      "====================\n",
      "\n",
      "Notes\n",
      "-----\n",
      "Data Set Characteristics:\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20  0.76     0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "This is a copy of UCI ML iris datasets.\n",
      "http://archive.ics.uci.edu/ml/datasets/Iris\n",
      "\n",
      "The famous Iris database, first used by Sir R.A Fisher\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      "References\n",
      "----------\n",
      "   - Fisher,R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   - Duda,R.O., & Hart,P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "     Structure and Classification Rule for Recognition in Partially Exposed\n",
      "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "     on Information Theory, May 1972, 431-433.\n",
      "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "     conceptual clustering system finds 3 classes in the data.\n",
      "   - Many, many more ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(data.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.fit(data.data, data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.predict([[3,3,3,3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.,  0.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.predict_proba([[3,3,3,3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini',\n",
       " 'splitter': 'best',\n",
       " 'max_depth': None,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'max_features': None,\n",
       " 'random_state': None,\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'class_weight': None,\n",
       " 'presort': False,\n",
       " 'n_features_': 4,\n",
       " 'n_outputs_': 1,\n",
       " 'classes_': array([0, 1, 2]),\n",
       " 'n_classes_': 3,\n",
       " 'max_features_': 4,\n",
       " 'tree_': <sklearn.tree._tree.Tree at 0x1a0971dc60>}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.__dict__ # json으로 dump 시켜서 모델의 재사용성이 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "316 µs ± 39.2 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit tree.fit(data.data, data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "data2 = sns.load_dataset('iris')\n",
    "label = LabelEncoder()\n",
    "label.fit_transform(data2.species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder()\n",
    "ohe.fit_transform(label.fit_transform(data2.species).reshape(-1, 1)).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'target_names', 'images', 'DESCR'])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n",
    "digits.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.data.shape\n",
    "# 이미지 데이터가 64개의 점으로 이루어져있다는 뜻 \n",
    "# 64라는 이미지 데이터를 8 X 8로 화면을 의미한다. 이러한 이미지 데이터가 1797라는 것을 의미한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.data.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optical Recognition of Handwritten Digits Data Set\n",
      "===================================================\n",
      "\n",
      "Notes\n",
      "-----\n",
      "Data Set Characteristics:\n",
      "    :Number of Instances: 5620\n",
      "    :Number of Attributes: 64\n",
      "    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\n",
      "    :Missing Attribute Values: None\n",
      "    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\n",
      "    :Date: July; 1998\n",
      "\n",
      "This is a copy of the test set of the UCI ML hand-written digits datasets\n",
      "http://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\n",
      "\n",
      "The data set contains images of hand-written digits: 10 classes where\n",
      "each class refers to a digit.\n",
      "\n",
      "Preprocessing programs made available by NIST were used to extract\n",
      "normalized bitmaps of handwritten digits from a preprinted form. From a\n",
      "total of 43 people, 30 contributed to the training set and different 13\n",
      "to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\n",
      "4x4 and the number of on pixels are counted in each block. This generates\n",
      "an input matrix of 8x8 where each element is an integer in the range\n",
      "0..16. This reduces dimensionality and gives invariance to small\n",
      "distortions.\n",
      "\n",
      "For info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\n",
      "T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\n",
      "L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\n",
      "1994.\n",
      "\n",
      "References\n",
      "----------\n",
      "  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\n",
      "    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\n",
      "    Graduate Studies in Science and Engineering, Bogazici University.\n",
      "  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\n",
      "  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\n",
      "    Linear dimensionalityreduction using relevance weighted LDA. School of\n",
      "    Electrical and Electronic Engineering Nanyang Technological University.\n",
      "    2005.\n",
      "  - Claudio Gentile. A New Approximate Maximal Margin Classification\n",
      "    Algorithm. NIPS. 2000.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 이미지 데이터를 수치화한 데이터로 pandas로 변경할 필요가 없다. 의미가 없다.\n",
    "print(digits.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797,)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, ..., 8, 9, 8])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### value count "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([178, 182, 177, 183, 181, 182, 181, 179, 174, 180])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.bincount(digits.target) \n",
    "# pandas value_count와 비슷한 것 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a09a06550>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.matshow(digits.data[0].reshape(8,8), cmap=plt.cm.Greys)\n",
    "# cmap=plt.cm.Greys: gray scale 로 그림을 그린다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1, 2, 3]\n",
    "b = ['a', 'b', 'c']\n",
    "c = zip(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'a'), (2, 'b'), (3, 'c')]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(4, 4) # 공간 \n",
    "\n",
    "for x,y,ax in zip(digits.data, digits.target, axes.ravel()):\n",
    "    ax.set_title(y)\n",
    "    ax.imshow(x.reshape(8,8), cmap = plt.cm.Greys)\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1257, 64)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9872712808273667"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99444444444444446"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a09bbe358>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_test[2].reshape(8,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.predict([X_test[2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 표준화: Removing mean and scaling variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "digits = load_digits()\n",
    "X, y = digits.data, digits.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.fit(X_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = scalar.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.2531274066082982e-18"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.fit_transform(X_train).mean() # 표준화 완료 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 기계 학습 과정\n",
    "***\n",
    "### 1. 데이터 불러오기 \n",
    "- pandas\n",
    "    1. info\n",
    "    2. descibe\n",
    "    3. head, tail, sample\n",
    "    4. groupby, plot\n",
    "- numpy 이용 \n",
    "    1. matplotlib\n",
    "\n",
    "\n",
    "### 2. 데이터 전처리 \n",
    "1. missing data\n",
    "2. duplicated\n",
    "   \n",
    "   \n",
    "### 3. 데이터 변환(ML 용)-> Numeric\n",
    "1. labelencoding\n",
    "2. onehotencoding\n",
    "\n",
    "\n",
    "### 4. 데이터 변환 (성능 향상 용)\n",
    "- Xsclar\n",
    "\n",
    "\n",
    "### 5. 데이터가 많은 때 \n",
    "1. train_test_split(overfitting 확인)\n",
    "\n",
    "\n",
    "### 6. 알고리즘 적용 \n",
    "1. from sklearn.알고리즘분류 import XClassify\n",
    "2. instance\n",
    "3. fit\n",
    "    1. Score, pca\n",
    "     \n",
    "### 7. 데이터가 적으면 (cross validation)\n",
    "<ul>\n",
    "    <li>전략: 10 folds</li>\n",
    "    <li>stratifed: 카테고리 별로 나눠줄 뿐만 아니라 비율도 맞춰준다.</li>\n",
    "    <li>shuffle 완전 random으로 중복을 허용</li>\n",
    "    <li>__최종모델은 아님!__</li>\n",
    "    <li>데이터 모델로 성능 예측</li>\n",
    "</ul>\n",
    "\n",
    "### Grid Search CV를 통한 hyperparameter찾기 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 성능 비교  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92105263157894735"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target)\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "knn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78947368421052633"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standard = StandardScaler()\n",
    "X_train_scalar = standard.fit_transform(X_train)\n",
    "X_test_scalar = standard.fit_transform(X_test)\n",
    "knn2 = KNeighborsClassifier()\n",
    "knn2.fit(X_train_scalar, y_train)\n",
    "knn2.score(X_test_scalar, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89473684210526316"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "minmax = MinMaxScaler()\n",
    "X_train_minmax = minmax.fit_transform(X_train)\n",
    "X_test_minmax = minmax.fit_transform(X_test)\n",
    "knn3= KNeighborsClassifier()\n",
    "knn3.fit(X_train_minmax, y_train)\n",
    "knn3.score(X_test_minmax, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Robust Scaling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89473684210526316"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "robust = RobustScaler()\n",
    "X_train_robust = robust.fit_transform(X_train)\n",
    "X_test_robust = robust.fit_transform(X_test)\n",
    "knn4=KNeighborsClassifier()\n",
    "knn4.fit(X_train_robust, y_train)\n",
    "knn4.score(X_test_robust, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94736842105263153"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(X_train)\n",
    "pca.fit(X_test)\n",
    "X_train_pca = pca.transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "knn5=KNeighborsClassifier()\n",
    "knn5.fit(X_train_pca, y_train)\n",
    "knn5.score(X_test_pca, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dimension transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=2, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2) # 4차원을 2차원으로 변경 \n",
    "pca.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1797, 2)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X.shape)\n",
    "X_pca = pca.transform(X)\n",
    "X_pca.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation\n",
    "\n",
    "\n",
    "1. 5개로 쪼갠다. (folds)\n",
    "2. 5가지의 test set을 만든다. \n",
    "3. 이 아이는 모든 데이터를 다 쓰면서 학습을 한다.\n",
    "4. 5가지 model의 정확도 평균\n",
    "\n",
    "\n",
    "모델의 성능 값을 통해서 overfitting을 확인한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0    1    2 ..., 1793 1794 1796] [  16   33   48   71   83   94   98  114  138  141  142  148  153  177  186\n",
      "  198  218  219  225  267  275  277  297  301  306  311  313  333  368  370\n",
      "  383  391  399  428  432  444  453  481  498  506  516  521  522  524  526\n",
      "  530  531  532  549  561  569  574  576  590  601  603  610  620  624  633\n",
      "  641  666  668  669  678  681  687  688  691  694  728  729  738  750  778\n",
      "  785  802  811  831  837  844  850  859  861  864  867  887  902  904  910\n",
      "  929  938  942  954  970  977  999 1014 1022 1028 1043 1048 1049 1052 1075\n",
      " 1078 1088 1097 1098 1100 1116 1147 1152 1156 1166 1185 1200 1225 1232 1234\n",
      " 1243 1245 1252 1265 1267 1274 1277 1279 1285 1298 1302 1304 1305 1319 1326\n",
      " 1342 1343 1382 1386 1391 1408 1432 1452 1474 1476 1481 1496 1500 1506 1510\n",
      " 1516 1517 1533 1551 1553 1568 1573 1574 1586 1592 1612 1626 1646 1647 1688\n",
      " 1695 1698 1703 1707 1708 1719 1733 1750 1760 1764 1766 1781 1787 1788 1795]\n",
      "[   0    1    2 ..., 1794 1795 1796] [   9   18   22   27   29   40   41   65   80   84   89   92  100  120  123\n",
      "  172  197  199  202  205  228  241  247  250  254  266  278  294  299  300\n",
      "  325  334  338  361  389  392  404  424  435  440  443  448  460  465  467\n",
      "  472  476  477  486  541  560  572  573  577  585  586  588  596  597  604\n",
      "  609  614  615  617  619  631  638  651  653  654  673  674  684  685  696\n",
      "  701  724  740  741  757  759  760  762  767  782  790  793  796  801  807\n",
      "  814  816  839  847  848  856  860  865  866  877  882  888  892  900  901\n",
      "  951  958  967  972  998 1002 1016 1039 1041 1053 1054 1067 1068 1072 1087\n",
      " 1108 1110 1121 1124 1126 1128 1138 1149 1155 1177 1178 1180 1192 1212 1223\n",
      " 1229 1238 1239 1256 1258 1259 1268 1269 1284 1355 1379 1387 1400 1401 1403\n",
      " 1405 1406 1427 1446 1460 1480 1497 1507 1509 1522 1536 1545 1552 1569 1580\n",
      " 1582 1584 1600 1606 1627 1656 1667 1674 1680 1697 1706 1717 1728 1784 1789]\n",
      "[   0    2    3 ..., 1794 1795 1796] [   1    4   14   15   26   36   50   55   75  107  125  130  136  140  149\n",
      "  157  166  168  170  171  174  189  204  214  231  232  237  258  261  274\n",
      "  279  285  286  296  298  305  316  329  331  336  350  351  364  365  374\n",
      "  379  403  417  425  464  466  469  470  474  490  496  504  505  511  514\n",
      "  519  529  533  554  559  581  584  598  618  642  658  663  670  672  675\n",
      "  676  702  705  713  749  753  777  795  803  857  868  869  880  893  899\n",
      "  908  917  923  941  945  963  964  976  981  989  993 1000 1001 1003 1006\n",
      " 1008 1011 1017 1021 1025 1031 1035 1046 1047 1076 1081 1093 1107 1109 1119\n",
      " 1129 1157 1162 1168 1170 1182 1186 1198 1204 1213 1227 1237 1241 1261 1306\n",
      " 1324 1346 1351 1359 1364 1367 1375 1399 1410 1411 1426 1434 1455 1463 1470\n",
      " 1475 1479 1491 1495 1503 1518 1537 1540 1543 1559 1563 1591 1609 1616 1629\n",
      " 1636 1638 1645 1648 1675 1692 1699 1702 1714 1722 1727 1748 1758 1772 1774]\n",
      "[   0    1    2 ..., 1794 1795 1796] [  10   21   47   67   68   72   73  101  108  128  133  134  146  147  160\n",
      "  164  176  209  242  243  255  260  263  265  268  273  280  288  307  310\n",
      "  312  321  322  326  335  341  358  373  381  385  407  419  423  426  436\n",
      "  437  438  450  451  479  489  491  534  544  548  553  556  557  579  583\n",
      "  587  592  599  607  632  647  656  662  680  711  714  722  761  773  774\n",
      "  799  818  820  853  862  871  878  886  890  891  897  909  913  926  940\n",
      "  946  955  969  971  973  985  986  987  996 1013 1038 1058 1061 1085 1091\n",
      " 1131 1172 1205 1210 1211 1215 1218 1220 1244 1247 1257 1278 1286 1288 1299\n",
      " 1308 1312 1316 1323 1325 1333 1337 1361 1366 1371 1376 1388 1393 1397 1402\n",
      " 1409 1419 1431 1443 1445 1451 1454 1459 1464 1467 1484 1486 1490 1499 1524\n",
      " 1526 1542 1547 1548 1550 1555 1557 1570 1571 1577 1583 1596 1608 1630 1637\n",
      " 1655 1658 1663 1685 1693 1696 1701 1740 1744 1749 1751 1754 1759 1767 1776]\n",
      "[   0    1    2 ..., 1792 1795 1796] [  13   19   20   43   56   60   62   74   86   96   99  102  106  161  175\n",
      "  180  182  190  200  207  210  212  238  259  281  282  289  292  309  339\n",
      "  348  360  393  394  406  410  413  420  452  455  456  471  478  497  502\n",
      "  512  525  540  546  552  563  571  622  629  636  637  646  648  652  657\n",
      "  671  693  704  707  710  718  721  730  734  745  756  770  783  808  819\n",
      "  829  830  832  835  840  842  845  852  863  872  873  876  896  898  905\n",
      "  925  937  939  952  956  960  984  988  990  995 1029 1032 1033 1060 1073\n",
      " 1082 1092 1104 1105 1111 1112 1123 1127 1153 1158 1163 1179 1190 1191 1194\n",
      " 1217 1224 1230 1248 1250 1263 1282 1283 1295 1311 1341 1345 1368 1370 1372\n",
      " 1374 1383 1385 1396 1398 1404 1414 1428 1437 1440 1444 1456 1473 1477 1492\n",
      " 1504 1515 1525 1532 1544 1564 1567 1578 1588 1595 1623 1625 1631 1642 1644\n",
      " 1659 1660 1679 1686 1709 1713 1715 1718 1724 1756 1768 1778 1791 1793 1794]\n",
      "[   0    1    2 ..., 1794 1795 1796] [   6   17   37   44   46   57   58   70   81   95   97  104  110  119  132\n",
      "  135  137  143  163  184  187  191  211  217  240  248  264  276  293  308\n",
      "  319  327  352  353  356  378  397  401  422  427  430  441  442  447  454\n",
      "  459  462  463  480  503  509  517  520  527  528  537  547  570  582  602\n",
      "  608  611  635  649  667  692  695  699  717  731  746  747  755  758  766\n",
      "  769  776  779  794  812  821  828  834  879  881  883  911  916  920  922\n",
      "  927  935  943  965  975  978  979  997 1010 1055 1070 1077 1080 1086 1103\n",
      " 1118 1132 1134 1143 1146 1151 1165 1176 1181 1184 1193 1195 1196 1208 1222\n",
      " 1231 1233 1260 1262 1275 1289 1296 1313 1317 1320 1327 1332 1339 1347 1352\n",
      " 1353 1362 1365 1380 1389 1395 1412 1416 1435 1447 1457 1462 1466 1469 1487\n",
      " 1489 1494 1501 1512 1513 1514 1521 1531 1535 1539 1541 1560 1590 1599 1601\n",
      " 1618 1634 1652 1662 1672 1681 1689 1716 1731 1735 1743 1745 1755 1773 1783]\n",
      "[   0    1    2 ..., 1794 1795 1796] [   3   23   25   30   32   39   61   77   87   88   91   93  111  124  131\n",
      "  162  167  169  185  188  203  213  224  227  269  270  271  291  295  303\n",
      "  315  318  320  332  340  343  349  354  369  372  388  400  409  415  418\n",
      "  429  431  433  439  446  473  492  499  515  535  565  578  589  591  595\n",
      "  612  613  616  626  627  664  682  690  703  726  736  739  752  763  764\n",
      "  787  789  792  797  810  823  824  836  838  854  894  906  953  974  992\n",
      " 1004 1007 1015 1018 1020 1023 1027 1030 1042 1095 1096 1099 1115 1141 1144\n",
      " 1148 1159 1183 1187 1201 1206 1209 1251 1264 1294 1297 1309 1335 1336 1356\n",
      " 1357 1363 1369 1377 1378 1384 1392 1407 1415 1424 1429 1430 1433 1449 1450\n",
      " 1458 1465 1472 1483 1485 1505 1511 1527 1528 1529 1530 1538 1549 1572 1575\n",
      " 1579 1585 1589 1597 1605 1610 1611 1628 1640 1650 1651 1654 1664 1669 1670\n",
      " 1671 1673 1678 1690 1704 1721 1723 1725 1729 1737 1742 1746 1775 1779 1780]\n",
      "[   1    3    4 ..., 1794 1795 1796] [   0    2   11   12   35   38   42   45   49   51   64   66   78   79   82\n",
      "   85   90  103  116  117  121  122  139  144  152  155  156  158  159  206\n",
      "  220  221  223  226  235  239  246  249  287  344  346  355  357  366  380\n",
      "  387  395  402  405  412  416  434  468  475  483  484  487  493  507  510\n",
      "  518  523  538  539  543  550  555  558  568  575  580  593  594  600  606\n",
      "  623  628  644  645  661  677  683  689  706  708  712  715  733  744  748\n",
      "  751  781  786  788  791  805  815  827  870  874  875  912  915  921  930\n",
      "  948  968  983  994 1012 1024 1026 1034 1036 1045 1056 1059 1063 1066 1071\n",
      " 1083 1106 1120 1136 1139 1150 1169 1173 1174 1175 1199 1214 1221 1228 1246\n",
      " 1249 1266 1271 1273 1281 1291 1301 1315 1330 1331 1334 1354 1360 1373 1423\n",
      " 1436 1441 1453 1478 1482 1488 1519 1554 1558 1561 1576 1581 1607 1614 1615\n",
      " 1617 1619 1635 1639 1653 1682 1683 1691 1739 1741 1747 1752 1765 1769]\n",
      "[   0    1    2 ..., 1794 1795 1796] [  24   31   53   54   59   63   76  105  113  118  145  151  154  178  181\n",
      "  192  193  195  201  215  222  230  234  236  253  272  283  284  290  302\n",
      "  304  317  323  328  330  337  347  362  363  367  371  375  376  384  386\n",
      "  390  396  398  408  414  445  457  482  485  488  500  513  542  562  605\n",
      "  621  625  630  639  643  650  660  686  697  698  700  716  719  723  727\n",
      "  732  735  737  742  765  768  771  775  804  809  813  817  826  833  843\n",
      "  846  849  885  889  903  907  918  919  924  931  933  934  959  966  982\n",
      "  991 1005 1019 1050 1057 1064 1069 1084 1094 1101 1102 1117 1125 1130 1154\n",
      " 1160 1167 1171 1188 1189 1197 1202 1203 1216 1235 1236 1240 1242 1253 1255\n",
      " 1270 1272 1293 1300 1303 1314 1321 1340 1344 1350 1390 1394 1421 1438 1439\n",
      " 1448 1461 1471 1493 1523 1546 1562 1593 1594 1602 1603 1613 1621 1641 1643\n",
      " 1649 1665 1687 1710 1711 1712 1726 1736 1757 1762 1771 1782 1786 1792]\n",
      "[   0    1    2 ..., 1793 1794 1795] [   5    7    8   28   34   52   69  109  112  115  126  127  129  150  165\n",
      "  173  179  183  194  196  208  216  229  233  244  245  251  252  256  257\n",
      "  262  314  324  342  345  359  377  382  411  421  449  458  461  494  495\n",
      "  501  508  536  545  551  564  566  567  634  640  655  659  665  679  709\n",
      "  720  725  743  754  772  780  784  798  800  806  822  825  841  851  855\n",
      "  858  884  895  914  928  932  936  944  947  949  950  957  961  962  980\n",
      " 1009 1037 1040 1044 1051 1062 1065 1074 1079 1089 1090 1113 1114 1122 1133\n",
      " 1135 1137 1140 1142 1145 1161 1164 1207 1219 1226 1254 1276 1280 1287 1290\n",
      " 1292 1307 1310 1318 1322 1328 1329 1338 1348 1349 1358 1381 1413 1417 1418\n",
      " 1420 1422 1425 1442 1468 1498 1502 1508 1520 1534 1556 1565 1566 1587 1598\n",
      " 1604 1620 1622 1624 1632 1633 1657 1661 1666 1668 1676 1677 1684 1694 1700\n",
      " 1705 1720 1730 1732 1734 1738 1753 1761 1763 1770 1777 1785 1790 1796]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kfold = KFold(10, shuffle=True) # 10 folds\n",
    "for x,t in kfold.split(X,y):\n",
    "    print(x,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.99444444,  0.98888889,  0.99444444,  0.98333333,  0.97222222,\n",
       "        0.98888889,  0.97777778,  0.98882682,  0.98324022,  0.98882682])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "knn6 = KNeighborsClassifier()\n",
    "cross_val_score(knn6,X,y, cv=kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.986644941030416"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(knn6,X,y, cv=kfold).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.95681063,  0.96494157,  0.96644295])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(knn6,X,y, cv=3) # folds 를 숫자로 해도 된다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델에서 어떠한 최적의 파라미터 선택\n",
    "grid search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'n_neighbors': [1, 2, 3, 4, 5, 6, 7]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "knn7 = KNeighborsClassifier()\n",
    "grid = GridSearchCV(knn7, param_grid={'n_neighbors':[1,2,3,4,5,6,7]})\n",
    "grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 3}"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_ # n = 3일 때 성능이 가장 좋다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=3, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_ # option을 통해서 best parameter를 찾을 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
