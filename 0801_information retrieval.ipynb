{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector Space Model\n",
    "- 벡터를 통해서 수치를 확인하여 누가 중요한지 선별 가능\n",
    "- pitcher: 나타난 횟수 (Term Frequency) 뿐만 아니라 나타난 문서의 수 (Document Frequency) 도 고려한다. \n",
    "- tf와 df를 고려하여 문서에서 단어의 수가 많으면 tf 증가, 많은 문서에서 나오게 되면 df가 증가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "from bs4 import BeautifulSoup\n",
    "import selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://media.daum.net/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def news_scrap1(URL):\n",
    "    headers = {\"Accept-Encoding\":\"false\"}\n",
    "    html = requests.get(URL)\n",
    "    URLStr = html.content.decode('utf-8')\n",
    "    return BeautifulSoup(URLStr, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMacro(URL):\n",
    "    dom = news_scrap1(URL)\n",
    "    urlList = dom.select(\".list_headline .tit_g a\")\n",
    "    for i in range(len(urlList)):\n",
    "        print(urlList[i].get_text())\n",
    "    return urlList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag = urlList[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    \"user-agent\":\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.99 Safari/537.36\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = [link.get('href') for link in urlList]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://v.media.daum.net/v/20180801145951917',\n",
       " 'http://v.media.daum.net/v/20180801145118652',\n",
       " 'http://v.media.daum.net/v/20180801144439453',\n",
       " 'http://v.media.daum.net/v/20180801144437449',\n",
       " 'http://v.media.daum.net/v/20180801144119329',\n",
       " 'http://v.media.daum.net/v/20180801143528088',\n",
       " 'http://v.media.daum.net/v/20180801143420047',\n",
       " 'http://v.media.daum.net/v/20180801142952883',\n",
       " 'http://v.media.daum.net/v/20180801142859853',\n",
       " 'http://v.media.daum.net/v/20180801141712421',\n",
       " 'http://v.media.daum.net/v/20180801141549383',\n",
       " 'http://v.media.daum.net/v/20180801141138247']"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "for link in links:\n",
    "    docid = link[-17:]\n",
    "    resp = requests.get(link, headers=headers)\n",
    "    html = BeautifulSoup(resp.text, \"lxml\")\n",
    "    content = html.select(\".article_view\")\n",
    "    \n",
    "    with open(\"doc/{0}.txt\".format(docid), 'w') as f:\n",
    "        f.write(content[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileList = glob.glob('doc/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(fileList[0], 'r') as fp:\n",
    "    content = fp.read()\n",
    "    content = content.strip()\n",
    "    content = re.sub(r'[\\s]{3,}',\"\", content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 우리가 만들어 보는 형태소 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence in nltk.sent_tokenize(content):\n",
    "    words = nltk.word_tokenize(sentence)\n",
    "    # print(words,\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence in nltk.sent_tokenize(content):\n",
    "    sentence  = re.sub(r'[\\s\\W]+','',sentence)\n",
    "    words = []\n",
    "    for i in range(len(sentence)):\n",
    "        words. append(sentence[i:i+2])\n",
    "        \n",
    "    # print(sentence, \"\\n\\n\")\n",
    "    # print(words, \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for sentence in nltk.sent_tokenize(content):\n",
    "    words = nltk.regexp_tokenize(sentence, r'[0-9ㄱ-ㅎㅏ-ㅣ가-힣]+')\n",
    "    \n",
    "    for word in words:\n",
    "        tokens = []\n",
    "        \n",
    "        for i in range(len(word)):\n",
    "            if i+1 < len(word):\n",
    "                tokens.append(word[i:i+2]) \n",
    "                # 한 글자만 나오는 것은 의미가 없기 때문에 제거한다.\n",
    "                # 형태소 분석기를 사용하지 않아도 우리가 만들어낼 수 있다. (조사, 신조어에 상관이 없다. )\n",
    "                \n",
    "        # print(word)\n",
    "        # print(tokens, \"\\n\\n\")\n",
    "    #print(words,\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 형태소 분석 모듈 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Kkma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Representation \n",
    "- 기사 안에서 나온 단어를 unique(set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniqueNouns = []\n",
    "for sentence in nltk.sent_tokenize(content):\n",
    "    nouns = []\n",
    "    for word in nltk.word_tokenize(sentence):\n",
    "        nouns.extend(Kkma().nouns(word))\n",
    "        nouns = list(set(nouns))\n",
    "    uniqueNouns.extend(nouns)\n",
    "    list(set(uniqueNouns))\n",
    "        \n",
    "#     words = Kkma().nouns(sentence) # 몇 번 나왔는지 확인을 하지 않는다. \n",
    "#     print(sentence)\n",
    "#     print(words,\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['18일',\n",
       " '2',\n",
       " '터미널',\n",
       " '뉴',\n",
       " '저',\n",
       " '첫날',\n",
       " '개항',\n",
       " '시스',\n",
       " '뉴시스',\n",
       " '훈',\n",
       " '공항',\n",
       " '국제공항',\n",
       " '여객',\n",
       " '인천공항',\n",
       " '18',\n",
       " '일',\n",
       " '기자',\n",
       " '인천',\n",
       " '오후',\n",
       " '2여객터미널',\n",
       " '항공',\n",
       " '인천국제공항',\n",
       " '임태훈',\n",
       " '임',\n",
       " '태',\n",
       " '이륙',\n",
       " '개',\n",
       " '찬선',\n",
       " '델타',\n",
       " '2',\n",
       " '터미널',\n",
       " '뉴',\n",
       " '저',\n",
       " '시스',\n",
       " '뉴시스',\n",
       " '공항',\n",
       " '10월',\n",
       " '7개',\n",
       " '여객',\n",
       " '프랑스',\n",
       " '홍',\n",
       " '중인',\n",
       " '인천공항',\n",
       " '홍찬선',\n",
       " '추가',\n",
       " '18',\n",
       " '기자',\n",
       " '인천',\n",
       " '10',\n",
       " '2여객터미널',\n",
       " '올',\n",
       " '항공',\n",
       " '사용',\n",
       " '월',\n",
       " '2018.1',\n",
       " '에어',\n",
       " '에어프랑스',\n",
       " '7',\n",
       " '네덜란드',\n",
       " '이전',\n",
       " '곳',\n",
       " '1일',\n",
       " '문제',\n",
       " '동계',\n",
       " '2',\n",
       " '2터미널',\n",
       " '터미널',\n",
       " '2018',\n",
       " '체크인',\n",
       " '시설',\n",
       " '1터미널',\n",
       " '결정',\n",
       " '재배치',\n",
       " '공항',\n",
       " '시즌',\n",
       " '동계시즌',\n",
       " '등',\n",
       " '21년',\n",
       " '21',\n",
       " '항공사',\n",
       " '중인',\n",
       " '부족',\n",
       " '고려',\n",
       " '카운터',\n",
       " '일',\n",
       " '상황',\n",
       " '인천',\n",
       " '진행',\n",
       " '증가',\n",
       " '당초',\n",
       " '항공',\n",
       " '7곳',\n",
       " '올해',\n",
       " '1',\n",
       " '공사',\n",
       " '예측',\n",
       " '인천공항공사',\n",
       " '체크인카운터',\n",
       " '년',\n",
       " '7',\n",
       " '이전',\n",
       " '샤먼',\n",
       " '가루',\n",
       " '체코항공',\n",
       " '에로플로트',\n",
       " '리딸',\n",
       " '2',\n",
       " '2터미널',\n",
       " '터미널',\n",
       " '에로',\n",
       " '코',\n",
       " '멕시코',\n",
       " '샤먼항공',\n",
       " '에로멕시코',\n",
       " '등',\n",
       " '항공사',\n",
       " '리',\n",
       " '체',\n",
       " '딸',\n",
       " '플로트',\n",
       " '항공',\n",
       " '중화',\n",
       " '중화항공',\n",
       " '이전',\n",
       " '대상',\n",
       " '개',\n",
       " '항공동맹체인',\n",
       " '2',\n",
       " '2터미널',\n",
       " '터미널',\n",
       " '환승편의',\n",
       " '조업',\n",
       " '지상',\n",
       " '저',\n",
       " '배치',\n",
       " '공항',\n",
       " '특성',\n",
       " '7개',\n",
       " '여객',\n",
       " '승',\n",
       " '등',\n",
       " '소속',\n",
       " '전용',\n",
       " '체인',\n",
       " '첨',\n",
       " '종합적',\n",
       " '전용공항',\n",
       " '항공사',\n",
       " '이',\n",
       " '운항',\n",
       " '집중',\n",
       " '스카이팀',\n",
       " '연계성',\n",
       " '팀',\n",
       " '시간',\n",
       " '원칙',\n",
       " '항공',\n",
       " '스카이',\n",
       " '편의',\n",
       " '공사',\n",
       " '선정',\n",
       " '만큼',\n",
       " '동맹',\n",
       " '평가',\n",
       " '환',\n",
       " '7',\n",
       " '라운지',\n",
       " '이전',\n",
       " '6개월간',\n",
       " '후',\n",
       " '분산',\n",
       " '실적',\n",
       " '전시간대',\n",
       " '2',\n",
       " '시설용량',\n",
       " '2터미널',\n",
       " '개월',\n",
       " '터미널',\n",
       " '나머지',\n",
       " '시설',\n",
       " '1터미널',\n",
       " '1월18일',\n",
       " '저',\n",
       " '간',\n",
       " '조사',\n",
       " '18시',\n",
       " '17',\n",
       " '분석',\n",
       " '운항',\n",
       " '6시',\n",
       " '개장',\n",
       " '6',\n",
       " '시',\n",
       " '집중',\n",
       " '18',\n",
       " '반면',\n",
       " '일',\n",
       " '오전',\n",
       " '전',\n",
       " '17시',\n",
       " '오후',\n",
       " '시간',\n",
       " '올해',\n",
       " '9시',\n",
       " '1',\n",
       " '9',\n",
       " '에만',\n",
       " '월',\n",
       " '결과',\n",
       " '특정',\n",
       " '용량',\n",
       " '시간대',\n",
       " '이전',\n",
       " '혼잡',\n",
       " '개',\n",
       " '처리',\n",
       " '수',\n",
       " '2',\n",
       " '2터미널',\n",
       " '터미널',\n",
       " '여객처리',\n",
       " '1터미널',\n",
       " '부담',\n",
       " '저',\n",
       " '이번',\n",
       " '7개',\n",
       " '여객',\n",
       " '첨',\n",
       " '기대',\n",
       " '항공사',\n",
       " '운항',\n",
       " '1',\n",
       " '공사',\n",
       " '완화',\n",
       " '가중',\n",
       " '7',\n",
       " '시간대',\n",
       " '개',\n",
       " '2',\n",
       " '델타',\n",
       " '2터미널',\n",
       " '터미널',\n",
       " '7개',\n",
       " '승',\n",
       " '소속',\n",
       " '공동',\n",
       " '프랑스',\n",
       " '항공사',\n",
       " '이',\n",
       " '중인',\n",
       " '동맹체',\n",
       " '환승',\n",
       " '스카이팀',\n",
       " '운항',\n",
       " '팀',\n",
       " '를',\n",
       " '진행',\n",
       " '코드',\n",
       " '항공',\n",
       " '스카이',\n",
       " '사용',\n",
       " '공동운항',\n",
       " '에어',\n",
       " '환',\n",
       " '에어프랑스',\n",
       " '7',\n",
       " '항공동맹체',\n",
       " '증가',\n",
       " '가능성',\n",
       " '올초',\n",
       " '오',\n",
       " '이',\n",
       " '초',\n",
       " '2',\n",
       " '2터미널',\n",
       " '개장',\n",
       " '터미널',\n",
       " '발생',\n",
       " '더',\n",
       " '승객',\n",
       " '도착',\n",
       " '이전',\n",
       " '올',\n",
       " '합동',\n",
       " '대',\n",
       " '언론',\n",
       " '오도착',\n",
       " '계획',\n",
       " '수단',\n",
       " '언론보도',\n",
       " '혼란',\n",
       " '내외',\n",
       " '티켓',\n",
       " '등',\n",
       " '승객',\n",
       " '문자메시지',\n",
       " '매체',\n",
       " '항공사',\n",
       " '광고매체',\n",
       " '최소화',\n",
       " '광고',\n",
       " '홍보수단',\n",
       " '문자',\n",
       " '공사',\n",
       " '오',\n",
       " '홍보',\n",
       " '활용',\n",
       " '보도',\n",
       " '메시지',\n",
       " '도착',\n",
       " '23년경',\n",
       " '인천국제공항공사',\n",
       " '완공',\n",
       " '수',\n",
       " '2',\n",
       " '2터미널',\n",
       " '터미널',\n",
       " '계획',\n",
       " '4단계',\n",
       " '균형',\n",
       " '재배치',\n",
       " '사장',\n",
       " '배치',\n",
       " '이번',\n",
       " '국제공항',\n",
       " '고',\n",
       " '이후',\n",
       " '정일',\n",
       " '정일영',\n",
       " '4',\n",
       " '단계',\n",
       " '항공사',\n",
       " '착공',\n",
       " '영',\n",
       " '인천',\n",
       " '대비',\n",
       " '성장',\n",
       " '확장',\n",
       " '올',\n",
       " '경',\n",
       " '23',\n",
       " '1',\n",
       " '마무리',\n",
       " '공사',\n",
       " '차질',\n",
       " '안정적',\n",
       " '하반기',\n",
       " '예상',\n",
       " '년',\n",
       " '사업',\n",
       " '추가']"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniqueNouns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
